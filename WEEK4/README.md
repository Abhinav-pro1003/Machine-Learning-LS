# ğŸ§  Next Word Predictor using Transformers

Final project for Week 4 of the NLP Course â€” bringing together classical ML, word embeddings, and transformer models (like GPT-2) for next-word prediction and sentence classification. This project demonstrates practical NLP techniques using real models and interactive deployment via Gradio.

---

## ğŸ“Œ Objectives

- Build a next-word prediction system using GPT-2
- Compare classical ML (TF-IDF + Logistic Regression) and embeddings (GloVe)
- Evaluate using accuracy and top-k predictions
- Deploy an interactive interface for users

---

## ğŸ—‚ï¸ Project Structure

Project.py


---

## ğŸ”§ Requirements

Install the required packages:

```bash
pip install -r requirements.txt
# OR manually:
pip install transformers torch gradio scikit-learn gensim pandas numpy nltk
